{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCJxUGoKDyGn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1AbUpkrrDeb5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pcz-pvmLDrW4"
      },
      "source": [
        "Download CelebA dataset and eval txt file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mduARJ_QDXp8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import urllib.request\n",
        "\n",
        "data_dir = \"/content/drive/MyDrive/\"\n",
        "zip_dir = \"/content/\"\n",
        "os.makedirs(zip_dir, exist_ok=True)\n",
        "\n",
        "zip_path = os.path.join(data_dir, \"celeba-hq-256.zip\")\n",
        "extracted_path = os.path.join(zip_dir, \"celeba-hq-256\")\n",
        "os.makedirs(extracted_path, exist_ok=True)\n",
        "\n",
        "data_dir = extracted_path\n",
        "\n",
        "if True:\n",
        "    print(\"Extracting files...\")\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "    print(\"Extraction complete!\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded and extracted!\")\n",
        "\n",
        "print(f\"Images are in: {extracted_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8utJ9z5sDTJA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "    def __init__(self, data_dir, partition_file, split='train', transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        with open(partition_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        self.image_labels = []\n",
        "        for line in lines:\n",
        "            image_name, partition = line.strip().split()\n",
        "            partition = int(partition)  # 0: train, 1: val, 2: test\n",
        "            if (split == 'train' and partition == 0) or \\\n",
        "               (split == 'val' and partition == 1) or \\\n",
        "               (split == 'test' and partition == 2):\n",
        "                self.image_labels.append(image_name)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.data_dir, self.image_labels[idx])\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "class CelebAHQ256(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "\n",
        "        file_list = os.listdir(data_dir)\n",
        "\n",
        "        self.img_list = []\n",
        "        for file in file_list:\n",
        "            if file.endswith('.jpg'):\n",
        "                file_num = int(file.split('.')[0])\n",
        "                if 0 <= file_num <= 29999:\n",
        "                    self.img_list.append(file)\n",
        "\n",
        "        self.img_list.sort()  # 00000~29999 순서로 정렬\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_list)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.data_dir, self.img_list[idx])\n",
        "        image = Image.open(img_name)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# transform 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda t: (t * 2) - 1)\n",
        "])\n",
        "\n",
        "# 데이터셋 생성\n",
        "train_dataset = CelebAHQ256(data_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pNjWONNjZ6Rp"
      },
      "outputs": [],
      "source": [
        "import torch, math\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from einops import *\n",
        "from einops.layers.torch import Rearrange\n",
        "from functools import partial\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, time_dim, theta=10000):\n",
        "        super().__init__()\n",
        "        self.time_dim = time_dim\n",
        "        self.theta = theta\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.time_dim // 2\n",
        "        emb = math.log(self.theta) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = time[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "class RMSNorm(nn.Module):\n",
        "    \"\"\"\n",
        "    Modified version of https://arxiv.org/abs/1910.07467\n",
        "    \"\"\"\n",
        "    def __init__(self, dim):\n",
        "        super(RMSNorm, self).__init__()\n",
        "        self.sqrt_dim = math.sqrt(dim)\n",
        "        self.gamma = nn.Parameter(torch.ones((1,dim,1,1)))\n",
        "\n",
        "    def forward(self, x):\n",
        "        normalized_x = F.normalize(x, dim=1)\n",
        "        return normalized_x * self.gamma * self.sqrt_dim\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1)\n",
        "        self.norm = RMSNorm(dim_out)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, time_cond=None):\n",
        "        x = self.conv(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if time_cond is not None:\n",
        "            scale, shift = time_cond\n",
        "            x = x * (scale + 1) + shift\n",
        "\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class Resnet(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, time_dim):\n",
        "        super(Resnet, self).__init__()\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_dim, dim_out * 2)\n",
        "        )\n",
        "\n",
        "        self.block1 = ResBlock(dim_in, dim_out)\n",
        "        self.block2 = ResBlock(dim_out, dim_out)\n",
        "        self.proj_conv = nn.Conv2d(dim_in, dim_out, 1)\n",
        "\n",
        "    def forward(self, x, time_emb):\n",
        "        time_cond = self.time_mlp(time_emb)\n",
        "        time_cond = rearrange(time_cond, 'n c -> n c 1 1')\n",
        "        time_cond = time_cond.chunk(2, dim=1)\n",
        "\n",
        "\n",
        "        f_x = self.block1(x, time_cond)\n",
        "        f_x = self.block2(f_x)\n",
        "\n",
        "        return f_x + self.proj_conv(x)#Residual\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads=4, channels_per_head=32):\n",
        "        super(Attention, self).__init__()\n",
        "        self.scale = dim ** -0.5\n",
        "        self.heads = heads\n",
        "        self.channels_per_head = channels_per_head\n",
        "\n",
        "        self.norm = RMSNorm(dim)\n",
        "        self.to_qkv = nn.Conv2d(dim, heads * channels_per_head * 3, 1, bias=False)\n",
        "        self.conv = nn.Conv2d(heads * channels_per_head, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        N, C, H, W = x.shape\n",
        "\n",
        "        x = self.norm(x)\n",
        "\n",
        "        qkv = self.to_qkv(x).chunk(3, dim=1)\n",
        "        q, k, v = map(lambda t: rearrange(t, \"b (h c) x y -> b h c (x y)\", h=self.heads), qkv)\n",
        "\n",
        "        score = torch.einsum(\"b h d i, b h d j -> b h i j\", q, k) * self.scale\n",
        "        score = score.softmax(dim=-1)\n",
        "\n",
        "        attn = torch.einsum(\"b h i j, b h d j -> b h i d\", score, v)\n",
        "        attn = rearrange(attn, 'b h (x y) d -> b (h d) x y', x=H, y=W)\n",
        "        return self.conv(attn)\n",
        "\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out, use_deconv=False):\n",
        "        super(Upsample, self).__init__()\n",
        "        self.up = None\n",
        "\n",
        "        if use_deconv:\n",
        "            self.up = nn.ConvTranspose2d(dim_in, dim_out, kernel_size=4, stride=2, padding=1)\n",
        "        else:\n",
        "            self.up = nn.Sequential(nn.Upsample(scale_factor=2, mode='nearest'),\n",
        "                                    nn.Conv2d(dim_in, dim_out, kernel_size=3, stride=1, padding=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.up(x)\n",
        "\n",
        "class Downsample(nn.Module):\n",
        "    def __init__(self, dim_in, dim_out):\n",
        "        super().__init__()\n",
        "        self.down = nn.Sequential(Rearrange(\"b c (h p1) (w p2) -> b (c p1 p2) h w\", p1=2, p2=2),\n",
        "                                  nn.Conv2d(dim_in * 4, dim_out, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.down(x)\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channel=3,\n",
        "                 dim1=64, #first channel\n",
        "                 dim_mults=(1, 2, 4, 8, 16), #Down: n-2 | Up: n-2\n",
        "                 emb_theta=10000,\n",
        "                 use_deconv=False,\n",
        "                 attn_heads=4,\n",
        "                 attn_channels_per_head=32,\n",
        "                 attn_num=None):\n",
        "        super(Unet, self).__init__()\n",
        "\n",
        "        # Dimensions\n",
        "        dim_multed = list(map(lambda t: t * dim1, dim_mults))\n",
        "        mid_dim = dim_multed[-1]\n",
        "\n",
        "        # Time embeddings\n",
        "        time_dim = dim1 * 4\n",
        "        time_encoder = SinusoidalPosEmb(dim1, theta=emb_theta)\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            time_encoder,\n",
        "            nn.Linear(dim1, time_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_dim, time_dim)\n",
        "        )\n",
        "\n",
        "        # NeuralNets\n",
        "        ResNet = partial(Resnet, time_dim=time_dim)\n",
        "        Attn = partial(Attention, heads=attn_heads, channels_per_head=attn_channels_per_head)\n",
        "        self.front_conv = nn.Conv2d(in_channel, dim1, kernel_size=7, padding=3)\n",
        "\n",
        "        self.downsamples = nn.ModuleList([])\n",
        "        self.upsamples = nn.ModuleList([])\n",
        "\n",
        "        # Set attention block number\n",
        "        dim_length = len(dim_multed[1:])\n",
        "\n",
        "        if attn_num is None:\n",
        "            attn_down_idx = 0\n",
        "            attn_up_idx = dim_length-1\n",
        "        else:\n",
        "            attn_down_idx = dim_length - attn_num\n",
        "            attn_up_idx = attn_num - 1\n",
        "\n",
        "        # Downsample\n",
        "        for dim_in, dim_out, idx in zip(dim_multed[:-1], dim_multed[1:], range(0,dim_length)):\n",
        "            last = (dim_length-1 == idx)\n",
        "\n",
        "            self.downsamples.append(nn.ModuleList([\n",
        "                ResNet(dim_in, dim_in),\n",
        "                ResNet(dim_in, dim_in),\n",
        "                Attn(dim_in) if idx >= attn_down_idx else nn.Identity(),\n",
        "                Downsample(dim_in, dim_out) if not last else nn.Conv2d(dim_in, dim_out, kernel_size=3, padding=1)\n",
        "            ]))\n",
        "\n",
        "        # Upsample\n",
        "        for dim_in, dim_out, idx in zip(*map(reversed, (dim_multed[1:], dim_multed[:-1], )), range(0,dim_length)):\n",
        "            last = (dim_length-1 == idx)\n",
        "\n",
        "            self.upsamples.append(nn.ModuleList([\n",
        "                ResNet(dim_in + dim_out, dim_in),\n",
        "                ResNet(dim_in + dim_out, dim_in),\n",
        "                Attn(dim_in) if idx <= attn_up_idx else nn.Identity(),\n",
        "                Upsample(dim_in, dim_out, use_deconv) if not last else nn.Conv2d(dim_in, dim_out, kernel_size=3, padding=1)\n",
        "            ]))\n",
        "\n",
        "        self.mid_resnet1 = ResNet(mid_dim, mid_dim)\n",
        "        self.mid_attn1 = Attn(mid_dim)\n",
        "        self.mid_resnet2 = ResNet(mid_dim, mid_dim)\n",
        "\n",
        "        self.end_resnet1 = nn.Conv2d(dim1*2, dim1, 1)\n",
        "        self.end_conv = nn.Sequential(nn.Conv2d(dim1, 64, 1), nn.Conv2d(64, in_channel, 1))\n",
        "\n",
        "    def forward(self, x, time):\n",
        "        t = self.time_mlp(time)\n",
        "        x = self.front_conv(x)\n",
        "        r = x.clone()\n",
        "\n",
        "        skip_con_buf = []\n",
        "\n",
        "        for net1, net2, attn, down in self.downsamples:\n",
        "            # Block1\n",
        "            x = net1(x, t)\n",
        "            skip_con_buf.append(x)\n",
        "\n",
        "            # Block2\n",
        "            x = net2(x, t)\n",
        "            if not isinstance(attn, nn.Identity): x = attn(x) + x # Attension block is just for score. so we need to add x to score.\n",
        "            skip_con_buf.append(x)\n",
        "\n",
        "            # Downsampling\n",
        "            x = down(x)\n",
        "\n",
        "        x = self.mid_resnet1(x, t)\n",
        "        x = self.mid_attn1(x)\n",
        "        x = self.mid_resnet2(x, t)\n",
        "\n",
        "        for net1, net2, attn, up in self.upsamples:\n",
        "            # Block1\n",
        "            x = torch.cat((x, skip_con_buf.pop()), dim=1)\n",
        "            x = net1(x, t)\n",
        "\n",
        "            # Block2\n",
        "            x = torch.cat((x, skip_con_buf.pop()), dim=1)\n",
        "            x = net2(x, t)\n",
        "            if not isinstance(attn, nn.Identity): x = attn(x) + x\n",
        "\n",
        "            # Upsampling\n",
        "            x = up(x)\n",
        "\n",
        "        x = torch.cat((x, r), dim=1)\n",
        "        x = self.end_resnet1(x)\n",
        "        x = self.end_conv(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-kj3zvWaACE"
      },
      "outputs": [],
      "source": [
        "import PIL, torch, PIL.Image\n",
        "from torchvision.transforms import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "img_to_tensor = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda t: (t*2)-1)\n",
        "])\n",
        "\n",
        "tensor_to_img = transforms.Compose([\n",
        "    transforms.Lambda(lambda t: (t+1)/2),\n",
        "    transforms.ToPILImage()\n",
        "])\n",
        "\n",
        "class ImageManager:\n",
        "    def __init__(self, path, format='png', use_clamp=True, transform_i_to_t=img_to_tensor, transform_t_to_i=tensor_to_img):\n",
        "        self.path = path\n",
        "        self.format = format\n",
        "        self.use_clamp = use_clamp\n",
        "        self.transform_i_to_t = transform_i_to_t\n",
        "        self.transform_t_to_i = transform_t_to_i\n",
        "\n",
        "        if use_clamp:\n",
        "            self.transform_adjust_range = transforms.Lambda(lambda x: torch.clamp(x, -1.0, 1.0))\n",
        "        else:\n",
        "            self.transform_adjust_range = transforms.Lambda(lambda x: ((x - x.amin(dim=(-3, -2, -1), keepdim=True)) / (x.amax(dim=(-3, -2, -1), keepdim=True) - x.amin(dim=(-3, -2, -1), keepdim=True)) - 0.5) * 2)\n",
        "\n",
        "        # Make dir\n",
        "        os.makedirs(self.path, exist_ok=True)\n",
        "\n",
        "    def save_plot(self, loss_hist, name, scatter=True):\n",
        "          plt.clf()\n",
        "          x = range(0,len(loss_hist))\n",
        "          if scatter: plt.scatter(x, loss_hist)\n",
        "          else: plt.plot(x, loss_hist)\n",
        "          plt.savefig(f'{self.path}/{name}.png')\n",
        "          plt.close()\n",
        "\n",
        "    def get_image(self, name):\n",
        "        img = PIL.Image.open(f'{self.path}/{name}.{self.format}')\n",
        "        img_tensor = self.transform_i_to_t(img)\n",
        "        return img_tensor\n",
        "\n",
        "    def save_img(self, tensors, name):\n",
        "        tensors = self.transform_adjust_range(tensors)\n",
        "\n",
        "        if tensors.dim() == 4:\n",
        "            idx = 0\n",
        "            for tensor in tensors:\n",
        "                img = self.transform_t_to_i(tensor)\n",
        "                img.save(f'{self.path}/{name}-{idx}.png')\n",
        "                idx += 1\n",
        "\n",
        "        else:\n",
        "            img = self.transform_t_to_i(tensors)\n",
        "            img.save(f'{self.path}/{name}.png')\n",
        "\n",
        "    def plot_images_with_spacing(self, tensors, name):\n",
        "        plt.clf()\n",
        "        N, B, C, H, W = tensors.shape\n",
        "\n",
        "        fig, axes = plt.subplots(B, N, figsize=(N * 3, 3 * B))\n",
        "\n",
        "        if B == 1:\n",
        "            axes = [axes]\n",
        "        elif N == 1:\n",
        "            axes = [[ax] for ax in axes]\n",
        "\n",
        "        for b_idx in range(B):\n",
        "            for n_idx in range(N):\n",
        "                tensor = tensors[n_idx, b_idx, :, :, :].unsqueeze(0)\n",
        "                tensor = self.transform_adjust_range(tensor).squeeze()\n",
        "                img = tensor_to_img(tensor)\n",
        "                axes[b_idx][n_idx].imshow(np.array(img))\n",
        "                axes[b_idx][n_idx].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{self.path}/{name}.png')\n",
        "        plt.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8g449n9Njuk"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.optim.lr_scheduler import _LRScheduler\n",
        "\n",
        "\"\"\"\n",
        "https://github.com/katsura-jp/pytorch-cosine-annealing-with-warmup/blob/master/cosine_annealing_warmup/scheduler.py\n",
        "\"\"\"\n",
        "\n",
        "class CosineAnnealingWarmupRestarts(_LRScheduler):\n",
        "    \"\"\"\n",
        "        optimizer (Optimizer): Wrapped optimizer.\n",
        "        first_cycle_steps (int): First cycle step size.\n",
        "        cycle_mult(float): Cycle steps magnification. Default: -1.\n",
        "        max_lr(float): First cycle's max learning rate. Default: 0.1.\n",
        "        min_lr(float): Min learning rate. Default: 0.001.\n",
        "        warmup_steps(int): Linear warmup step size. Default: 0.\n",
        "        gamma(float): Decrease rate of max learning rate by cycle. Default: 1.\n",
        "        last_epoch (int): The index of last epoch. Default: -1.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 optimizer : torch.optim.Optimizer,\n",
        "                 first_cycle_steps : int,\n",
        "                 cycle_mult : float = 1.,\n",
        "                 max_lr : float = 0.1,\n",
        "                 min_lr : float = 0.001,\n",
        "                 warmup_steps : int = 0,\n",
        "                 gamma : float = 1.,\n",
        "                 last_epoch : int = -1\n",
        "        ):\n",
        "        assert warmup_steps < first_cycle_steps\n",
        "\n",
        "        self.first_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle_mult = cycle_mult # cycle steps magnification\n",
        "        self.base_max_lr = max_lr # first max learning rate\n",
        "        self.max_lr = max_lr # max learning rate in the current cycle\n",
        "        self.min_lr = min_lr # min learning rate\n",
        "        self.warmup_steps = warmup_steps # warmup step size\n",
        "        self.gamma = gamma # decrease rate of max learning rate by cycle\n",
        "\n",
        "        self.cur_cycle_steps = first_cycle_steps # first cycle step size\n",
        "        self.cycle = 0 # cycle count\n",
        "        self.step_in_cycle = last_epoch # step size of the current cycle\n",
        "\n",
        "        super(CosineAnnealingWarmupRestarts, self).__init__(optimizer, last_epoch)\n",
        "\n",
        "        # set learning rate min_lr\n",
        "        self.init_lr()\n",
        "\n",
        "    def init_lr(self):\n",
        "        self.base_lrs = []\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.min_lr\n",
        "            self.base_lrs.append(self.min_lr)\n",
        "\n",
        "    def get_lr(self):\n",
        "        if self.step_in_cycle == -1:\n",
        "            return self.base_lrs\n",
        "        elif self.step_in_cycle < self.warmup_steps:\n",
        "            return [(self.max_lr - base_lr)*self.step_in_cycle / self.warmup_steps + base_lr for base_lr in self.base_lrs]\n",
        "        else:\n",
        "            return [base_lr + (self.max_lr - base_lr) \\\n",
        "                    * (1 + math.cos(math.pi * (self.step_in_cycle-self.warmup_steps) \\\n",
        "                                    / (self.cur_cycle_steps - self.warmup_steps))) / 2\n",
        "                    for base_lr in self.base_lrs]\n",
        "\n",
        "    def step(self, epoch=None):\n",
        "        if epoch is None:\n",
        "            epoch = self.last_epoch + 1\n",
        "            self.step_in_cycle = self.step_in_cycle + 1\n",
        "            if self.step_in_cycle >= self.cur_cycle_steps:\n",
        "                self.cycle += 1\n",
        "                self.step_in_cycle = self.step_in_cycle - self.cur_cycle_steps\n",
        "                self.cur_cycle_steps = int((self.cur_cycle_steps - self.warmup_steps) * self.cycle_mult) + self.warmup_steps\n",
        "        else:\n",
        "            if epoch >= self.first_cycle_steps:\n",
        "                if self.cycle_mult == 1.:\n",
        "                    self.step_in_cycle = epoch % self.first_cycle_steps\n",
        "                    self.cycle = epoch // self.first_cycle_steps\n",
        "                else:\n",
        "                    n = int(math.log((epoch / self.first_cycle_steps * (self.cycle_mult - 1) + 1), self.cycle_mult))\n",
        "                    self.cycle = n\n",
        "                    self.step_in_cycle = epoch - int(self.first_cycle_steps * (self.cycle_mult ** n - 1) / (self.cycle_mult - 1))\n",
        "                    self.cur_cycle_steps = self.first_cycle_steps * self.cycle_mult ** (n)\n",
        "            else:\n",
        "                self.cur_cycle_steps = self.first_cycle_steps\n",
        "                self.step_in_cycle = epoch\n",
        "\n",
        "        self.max_lr = self.base_max_lr * (self.gamma**self.cycle)\n",
        "        self.last_epoch = math.floor(epoch)\n",
        "        for param_group, lr in zip(self.optimizer.param_groups, self.get_lr()):\n",
        "            param_group['lr'] = lr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AtuRTSITaC-4"
      },
      "outputs": [],
      "source": [
        "import torch, time, math, os\n",
        "from torch.optim import Adam\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "def linear_beta_scheduler(beta_start, beta_end, timesteps):\n",
        "    return torch.linspace(beta_start, beta_end, timesteps)\n",
        "\n",
        "def extract(a, t, x_shape):\n",
        "    b, *_ = t.shape\n",
        "    out = a.gather(-1, t)\n",
        "    return out.reshape(b, *((1,) * (len(x_shape) - 1)))\n",
        "\n",
        "class GaussianDiffusion(nn.Module):\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 beta_start=0.0001,\n",
        "                 beta_end=0.02,\n",
        "                 timesteps=1000,\n",
        "                 device=device,\n",
        "                 save_per_p_steps=100\n",
        "                 ):\n",
        "        super(GaussianDiffusion, self).__init__()\n",
        "        self.device = device\n",
        "        self.timesteps = timesteps\n",
        "        self.save_per_p_steps = save_per_p_steps\n",
        "\n",
        "        # Basic components\n",
        "        betas = linear_beta_scheduler(beta_start, beta_end, timesteps).to(self.device)\n",
        "        alphas = 1. - betas\n",
        "        alphas_bar = torch.cumprod(alphas, dim=0)\n",
        "        alphas_bar_prev = F.pad(alphas_bar[:-1], (1, 0), value = 1.)\n",
        "        sqrt_one_minus_alphas_bar = torch.sqrt(1. - alphas_bar)\n",
        "\n",
        "        register_buffer = lambda name, val: self.register_buffer(name, val.to(torch.float32)) #buffer for coefficients\n",
        "\n",
        "        # Register basic components in buffer\n",
        "        register_buffer('betas', betas)\n",
        "        register_buffer('alphas_bar', alphas_bar)\n",
        "        register_buffer('alphas_bar_prev', alphas_bar_prev)\n",
        "\n",
        "        # Register coefficients components in buffer\n",
        "        register_buffer('sqrt_alphas_bar', torch.sqrt(alphas_bar))\n",
        "        register_buffer('sqrt_one_minus_alphas_bar', sqrt_one_minus_alphas_bar)\n",
        "        register_buffer('one_minus_alphas', 1. - alphas)\n",
        "        register_buffer('sqrt_alphas_recip', torch.sqrt(1/alphas))\n",
        "        register_buffer('coef_pred_noise', betas / sqrt_one_minus_alphas_bar)\n",
        "\n",
        "        posterior_variance = betas * (1. - alphas_bar_prev) / (1. - alphas_bar)\n",
        "\n",
        "        register_buffer('sqrt_posterior_variance', torch.sqrt(posterior_variance))\n",
        "\n",
        "        self.model = model.to(device)\n",
        "\n",
        "    def q_sample(self, x, time, noise=None):\n",
        "        \"\"\"\n",
        "        q(x_t | x_t-1) : forward process\n",
        "        \"\"\"\n",
        "        x_shape = x.shape\n",
        "        x = x.to(self.device)\n",
        "        time = time.to(self.device)\n",
        "\n",
        "        assert x_shape[0] == time.shape[0], 'mismatch of tensor shape'\n",
        "\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x, device=self.device)\n",
        "\n",
        "        sqrt_alphas_bar_t = extract(self.alphas_bar, time, x_shape)\n",
        "        sqrt_one_minus_alphas_bar_t = extract(self.sqrt_one_minus_alphas_bar, time, x_shape)\n",
        "\n",
        "        noisy_x = sqrt_alphas_bar_t * x + sqrt_one_minus_alphas_bar_t * noise\n",
        "\n",
        "        return noisy_x\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def p_sample(self, x):\n",
        "        \"\"\"\n",
        "        p(x_0 | x_T) : denoise process\n",
        "        \"\"\"\n",
        "        N, C, H, W = x.shape\n",
        "        xs = []\n",
        "\n",
        "        for i in range(self.timesteps-1, -1, -1):\n",
        "            t = torch.ones((N,), dtype=torch.int64, device=self.device) * i\n",
        "            if (i+1) % self.save_per_p_steps == 0: xs.append(x)\n",
        "\n",
        "            sqrt_alphas_recip_t = extract(self.sqrt_alphas_recip, t, x.shape)\n",
        "            one_minus_alphas_t = extract(self.one_minus_alphas, t, x.shape)\n",
        "            sqrt_one_minus_alphas_bar_t = extract(self.sqrt_one_minus_alphas_bar, t, x.shape)\n",
        "            sqrt_posterior_variance_t = extract(self.sqrt_posterior_variance, t, x.shape)\n",
        "\n",
        "            pred_noise = self.model(x, t)\n",
        "            noise = torch.randn_like(x, device=self.device)\n",
        "\n",
        "            x_mean = sqrt_alphas_recip_t * (x - pred_noise * one_minus_alphas_t / sqrt_one_minus_alphas_bar_t)\n",
        "            x_var = sqrt_posterior_variance_t * noise\n",
        "\n",
        "            x = x_mean + x_var\n",
        "\n",
        "        xs.append(x)\n",
        "\n",
        "        xs = torch.stack(xs)\n",
        "\n",
        "        return xs\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self,\n",
        "                 diffusion_model,\n",
        "                 dataset,\n",
        "                 save_path,\n",
        "                 save_name,\n",
        "                 lr_scheduler=None,  # 함수 (callable) or None\n",
        "                 batch_size=16,\n",
        "                 shuffle=True,\n",
        "                 ep=10,\n",
        "                 lr=1e-4,\n",
        "                 betas=(0.9, 0.999),\n",
        "                 accumulation_steps=1,\n",
        "                 device='cuda',\n",
        "                 sample_num=1,\n",
        "                 save_interval_steps=500,\n",
        "                 track_hist=False,\n",
        "                 use_p2=True,\n",
        "                 p2_gamma=0.5,\n",
        "                 loss_func=F.mse_loss,\n",
        "                 imagemanager=None):\n",
        "\n",
        "        self.device = device\n",
        "        self.timesteps = diffusion_model.timesteps\n",
        "        self.accumulation_steps = accumulation_steps\n",
        "        self.save_interval_steps = save_interval_steps\n",
        "\n",
        "        # 기본 구성\n",
        "        self.grad_update = 0\n",
        "        self.total_train_time_prev = 0\n",
        "        self.total_train_time = 0\n",
        "        self.save_name = save_name\n",
        "        self.save_path = save_path\n",
        "        self.imagemanager = imagemanager\n",
        "        self.ep = ep\n",
        "        self.dataloader = DataLoader(dataset, batch_size, shuffle=shuffle)\n",
        "\n",
        "        # 모델 및 옵티마이저\n",
        "        self.diffusion_model = diffusion_model\n",
        "        self.optim = Adam(self.diffusion_model.model.parameters(), lr=lr, betas=betas)\n",
        "\n",
        "        # 스케줄러 함수 저장만\n",
        "        self.lr_scheduler_fn = lr_scheduler\n",
        "        self.lr_scheduler = None  # 실제 스케줄러는 load or train에서 생성\n",
        "\n",
        "        self.use_p2 = use_p2\n",
        "        self.p2_gamma = p2_gamma\n",
        "        self.loss_func = loss_func\n",
        "        self.loss = self.p2_weighting_loss if use_p2 else loss_func\n",
        "\n",
        "        self.sample_num = sample_num\n",
        "        self.track_hist = track_hist\n",
        "        self.hist = []\n",
        "        self.hist_mean = []\n",
        "\n",
        "    def save(self):\n",
        "        save_dict = {\n",
        "            'model_state_dict': self.diffusion_model.model.state_dict(),\n",
        "            'optim_state_dict': self.optim.state_dict(),\n",
        "            'grad_update': self.grad_update,\n",
        "            'total_train_time': self.total_train_time + self.total_train_time_prev\n",
        "        }\n",
        "        if self.lr_scheduler is not None:\n",
        "            save_dict['lr_scheduler_state_dict'] = self.lr_scheduler.state_dict()\n",
        "\n",
        "        torch.save(save_dict, f'{self.save_path}/{self.save_name}.pt')\n",
        "\n",
        "    def load(self, current_step_for_scheduler=None):\n",
        "        checkpoint = torch.load(f'{self.save_path}/{self.save_name}.pt', map_location=self.device)\n",
        "\n",
        "        self.diffusion_model.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optim.load_state_dict(checkpoint['optim_state_dict'])\n",
        "        self.grad_update = checkpoint['grad_update']\n",
        "        self.total_train_time_prev = checkpoint['total_train_time']\n",
        "\n",
        "        # 스케줄러 새로 초기화 (함수였다면)\n",
        "        if self.lr_scheduler_fn is not None and self.lr_scheduler is None:\n",
        "            self.lr_scheduler = self.lr_scheduler_fn(self.optim)\n",
        "\n",
        "        # 스케줄러가 이미 있고 저장된 상태가 있으면 로드\n",
        "        if self.lr_scheduler is not None and 'lr_scheduler_state_dict' in checkpoint:\n",
        "            self.lr_scheduler.load_state_dict(checkpoint['lr_scheduler_state_dict'])\n",
        "\n",
        "        # 없으면 step 위치라도 맞춰주자 (warmup start)\n",
        "        elif self.lr_scheduler is not None and current_step_for_scheduler is not None:\n",
        "            self.lr_scheduler.step(current_step_for_scheduler)\n",
        "\n",
        "    def ensure_scheduler_ready(self, current_step_for_scheduler=None):\n",
        "        # scheduler가 아직 정의되지 않은 경우 init (load 안 한 경우)\n",
        "        if self.lr_scheduler is None and self.lr_scheduler_fn is not None:\n",
        "            self.lr_scheduler = self.lr_scheduler_fn(self.optim)\n",
        "            if current_step_for_scheduler is not None:\n",
        "                self.lr_scheduler.step(current_step_for_scheduler)\n",
        "\n",
        "    def p2_weighting_loss(self, pred_noise, noise, time):\n",
        "        N, C, H, W = noise.shape\n",
        "        alpha_bar_t = extract(self.diffusion_model.alphas_bar, time, noise.shape)\n",
        "        p2_weight =  (1 - alpha_bar_t) ** self.p2_gamma\n",
        "        loss = self.loss_func(pred_noise, noise, reduction='none').mean(dim=[1, 2, 3])\n",
        "        loss = p2_weight * loss\n",
        "        return loss.mean()\n",
        "\n",
        "    def train(self):\n",
        "        max_itera = len(self.dataloader)\n",
        "        start_time = time.time()\n",
        "\n",
        "        for ep in range(0, self.ep):\n",
        "            process_bar = tqdm(zip(self.dataloader, range(0, max_itera)), desc=f\"Training (Epoch {ep+1}/{self.ep})\", ncols=1000)\n",
        "            self.optim.zero_grad()\n",
        "            for data, itera in process_bar:\n",
        "                N, C, H, W = data.shape\n",
        "                x = data\n",
        "\n",
        "                # t, epsilon\n",
        "                random_t = torch.randint(0, self.timesteps, (N,), device=self.device)\n",
        "                noise = torch.randn_like(x, device=self.device)\n",
        "\n",
        "                # q(x_t | x_0)\n",
        "                noisy_x = self.diffusion_model.q_sample(x=x, time=random_t, noise=noise)\n",
        "\n",
        "                # Predict Noise\n",
        "                pred_noise = self.diffusion_model.model(noisy_x, random_t)\n",
        "\n",
        "                # Loss\n",
        "                if self.use_p2: loss = self.loss(pred_noise, noise, random_t) / self.accumulation_steps\n",
        "                else: loss = self.loss(pred_noise, noise) / self.accumulation_steps\n",
        "\n",
        "                # Process description\n",
        "                process_bar.set_postfix(\n",
        "                loss=str(float(loss))[:6],\n",
        "                lr=f\"{self.optim.param_groups[0]['lr']:.1e}\",\n",
        "                grad_update=self.grad_update\n",
        "                )\n",
        "\n",
        "                # Train\n",
        "                loss.backward()\n",
        "                if (itera+1) % self.accumulation_steps == 0:\n",
        "\n",
        "                    # Track hist\n",
        "                    if self.track_hist: self.hist.append(float(loss))\n",
        "\n",
        "                    # Optimize\n",
        "                    self.grad_update += 1\n",
        "                    self.optim.step()\n",
        "                    if self.lr_scheduler is not None: self.lr_scheduler.step()\n",
        "                    self.optim.zero_grad()\n",
        "\n",
        "                if (itera+1) % self.save_interval_steps == 0:\n",
        "                    # Save model\n",
        "                    self.total_train_time = time.time() - start_time\n",
        "                    self.save()\n",
        "\n",
        "                    if self.sample_num != 0 and (itera+1) % (self.save_interval_steps*3) == 0:\n",
        "                        # Sampling : p(x_0 | x_T)\n",
        "                        gaussian_noise = torch.randn((self.sample_num, C, H, W), device=self.device)\n",
        "                        generated_samples = self.diffusion_model.p_sample(gaussian_noise)\n",
        "\n",
        "                        # Save generated images\n",
        "                        self.imagemanager.plot_images_with_spacing(generated_samples, f'p_sample_{ep}_{itera+1}')\n",
        "\n",
        "                    # Track hist\n",
        "                    if self.track_hist:\n",
        "                        loss_mean = sum(self.hist) / len(self.hist)\n",
        "                        self.hist_mean.append(loss_mean)\n",
        "\n",
        "                        # Save hist\n",
        "                        self.imagemanager.save_plot(self.hist_mean, 'mean_hist')\n",
        "                        self.imagemanager.save_plot(self.hist, 'hist')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KNK-QyPEczZ",
        "outputId": "6a4cb671-afec-4ec1-d092-3fb0909756a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training (Epoch 1/100): 7500it [2:04:09,  1.01it/s, grad_update=63499, loss=0.0003, lr=1.0e-04]\n",
            "Training (Epoch 2/100): 7500it [2:03:53,  1.01it/s, grad_update=65374, loss=0.0026, lr=1.0e-04]\n",
            "Training (Epoch 3/100): 574it [08:58,  1.09it/s, grad_update=65518, loss=0.0047, lr=1.0e-04]"
          ]
        }
      ],
      "source": [
        "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
        "unet = Unet(in_channel=3, dim1=64, dim_mults=(1,2,2,4,4,6,6), attn_num=3)#1,2,2,4,4,8,8\n",
        "diffusionModel = GaussianDiffusion(model=unet)\n",
        "imageManager = ImageManager(path='/content/drive/MyDrive/results', use_clamp=False)\n",
        "\n",
        "lr = 1.e-4\n",
        "\n",
        "lr_scheduler = lambda optim: CosineAnnealingWarmupRestarts(\n",
        "    optimizer=optim,\n",
        "    first_cycle_steps=500,\n",
        "    cycle_mult=2.0,\n",
        "    max_lr=lr,\n",
        "    min_lr=1e-6,\n",
        "    warmup_steps=100,\n",
        "    gamma=0.9\n",
        ")\n",
        "\n",
        "lr_scheduler = lambda optim: get_cosine_schedule_with_warmup(\n",
        "    optimizer=optim,\n",
        "    num_training_steps=500_000,\n",
        "    num_warmup_steps=2_000\n",
        ")\n",
        "\n",
        "trainer = Trainer(diffusion_model=diffusionModel,\n",
        "                  dataset=train_dataset,\n",
        "                  save_path='/content/drive/MyDrive/hist',\n",
        "                  save_name='Diffusion_celeba-hq_1000T_cosine',\n",
        "                  batch_size=4,\n",
        "                  lr_scheduler=lr_scheduler,\n",
        "                  lr=lr,\n",
        "                  loss_func=F.mse_loss,\n",
        "                  accumulation_steps=4,\n",
        "                  use_p2=False,\n",
        "                  save_interval_steps=500,\n",
        "                  sample_num=1,\n",
        "                  ep=100,\n",
        "                  imagemanager=imageManager,\n",
        "                  track_hist=True)\n",
        "\n",
        "trainer.load() # scheduler 넣고 첫 load일 때만 current step 맞춰주면 됨.\n",
        "# trainer.ensure_scheduler_ready() # load하지 않고 lr_scheduler을 사용할 때\n",
        "trainer.train()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
